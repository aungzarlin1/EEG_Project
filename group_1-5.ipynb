{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35b25df7-9847-40e7-808a-cb4bd790d4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fab853f8-75d2-4c79-b223-64d4da122cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.load('./y/g1dual1_y.npy').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd2b50d7-dcac-4362-8996-39d8faa09758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = './y/'\n",
    "# label = []\n",
    "# for filename in sorted(os.listdir(path)):\n",
    "#     f = os.path.join(path, filename)\n",
    "#     y = np.load(f)\n",
    "#     print(y.shape)\n",
    "#     label = np.hstack((label, y))\n",
    "\n",
    "# print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6586f3aa-3d10-4baf-acca-88f4fc84ae69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = './data/'\n",
    "# filename = sorted(os.listdir(path))[0]\n",
    "# f = os.path.join(path, filename)\n",
    "# data = np.load(f)\n",
    "# print(data.shape)\n",
    "\n",
    "# for filename in sorted(os.listdir(path)):\n",
    "#     if filename == 'g1dual1_X.npy':\n",
    "#         print(filename)\n",
    "#         continue\n",
    "#     f = os.path.join(path, filename)\n",
    "#     x = np.load(f)\n",
    "#     print(x.shape)\n",
    "#     data = np.concatenate((data, x), axis=0)\n",
    "\n",
    "# # print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "079b6454-55a5-4115-9e3f-7bce02697fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4896a11-1a95-4703-a1f9-87cac4b2fb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('./data/data.npy', data)\n",
    "# np.save('./data/label.npy', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8eb69f03-34ac-4f77-bcb6-f46bab816bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7164, 32, 410)\n",
      "(7164,)\n"
     ]
    }
   ],
   "source": [
    "X = np.load('./data/data.npy')\n",
    "y = np.load('./data/label.npy')\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b54a1ac7-f779-4696-b0d6-90d33d5c473c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('ERP + MDM', Pipeline(steps=[('erpcovariances', ERPCovariances(estimator='oas')),\n",
      "                ('mdm', MDM())])), ('Xdawn + RegLDA', Pipeline(steps=[('xdawncovariances',\n",
      "                 XdawnCovariances(estimator='oas', nfilter=3)),\n",
      "                ('vectorizer',\n",
      "                 <mne.decoding.transformer.Vectorizer object at 0x7f4aefb3baf0>),\n",
      "                ('lineardiscriminantanalysis',\n",
      "                 LinearDiscriminantAnalysis(shrinkage='auto', solver='eigen'))])), ('Xdawn + MDM', Pipeline(steps=[('xdawncovariances',\n",
      "                 XdawnCovariances(estimator='oas', nfilter=3)),\n",
      "                ('mdm', MDM())])), ('Xdawn + SVM', Pipeline(steps=[('xdawncovariances',\n",
      "                 XdawnCovariances(estimator='oas', nfilter=3)),\n",
      "                ('vectorizer',\n",
      "                 <mne.decoding.transformer.Vectorizer object at 0x7f4ab7e34f40>),\n",
      "                ('svc', SVC())]))])\n",
      "(7164, 32, 410) (7164,)\n",
      "(7164, 32, 410) (7164,)\n",
      "(7164, 32, 410) (7164,)\n",
      "(7164, 32, 410) (7164,)\n",
      "(7164, 32, 410) (7164,)\n",
      "ERP + MDM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Non-target       0.86      0.58      0.69      5970\n",
      "     targets       0.20      0.53      0.29      1194\n",
      "\n",
      "    accuracy                           0.57      7164\n",
      "   macro avg       0.53      0.55      0.49      7164\n",
      "weighted avg       0.75      0.57      0.62      7164\n",
      "\n",
      "(7164, 32, 410) (7164,)\n",
      "(7164, 32, 410) (7164,)\n",
      "(7164, 32, 410) (7164,)\n",
      "(7164, 32, 410) (7164,)\n",
      "(7164, 32, 410) (7164,)\n",
      "Xdawn + RegLDA\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Non-target       0.88      0.96      0.92      5970\n",
      "     targets       0.64      0.31      0.42      1194\n",
      "\n",
      "    accuracy                           0.86      7164\n",
      "   macro avg       0.76      0.64      0.67      7164\n",
      "weighted avg       0.84      0.86      0.83      7164\n",
      "\n",
      "(7164, 32, 410) (7164,)\n",
      "(7164, 32, 410) (7164,)\n",
      "(7164, 32, 410) (7164,)\n",
      "(7164, 32, 410) (7164,)\n",
      "(7164, 32, 410) (7164,)\n",
      "Xdawn + MDM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Non-target       0.91      0.71      0.80      5970\n",
      "     targets       0.31      0.64      0.41      1194\n",
      "\n",
      "    accuracy                           0.70      7164\n",
      "   macro avg       0.61      0.67      0.60      7164\n",
      "weighted avg       0.81      0.70      0.73      7164\n",
      "\n",
      "(7164, 32, 410) (7164,)\n",
      "(7164, 32, 410) (7164,)\n",
      "(7164, 32, 410) (7164,)\n",
      "(7164, 32, 410) (7164,)\n",
      "(7164, 32, 410) (7164,)\n",
      "Xdawn + SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Non-target       0.83      1.00      0.91      5970\n",
      "     targets       0.75      0.00      0.01      1194\n",
      "\n",
      "    accuracy                           0.83      7164\n",
      "   macro avg       0.79      0.50      0.46      7164\n",
      "weighted avg       0.82      0.83      0.76      7164\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from mne.preprocessing import Xdawn\n",
    "from pyriemann.estimation import ERPCovariances\n",
    "from collections import OrderedDict\n",
    "from pyriemann.classification import MDM\n",
    "from pyriemann.estimation import XdawnCovariances\n",
    "from sklearn.metrics import classification_report\n",
    "from mne.decoding import Vectorizer\n",
    "from sklearn.model_selection import cross_val_score, StratifiedShuffleSplit\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "lda = LDA(shrinkage='auto', solver='eigen') #Regularized LDA\n",
    "svc = SVC(kernel = 'rbf')\n",
    "\n",
    "clfs = OrderedDict()\n",
    "\n",
    "n_components = 3\n",
    "\n",
    "clfs['ERP + MDM'] = make_pipeline(ERPCovariances(estimator='oas'), MDM())\n",
    "clfs['Xdawn + RegLDA'] = make_pipeline(XdawnCovariances(n_components, \n",
    "                            estimator='oas'), Vectorizer(), lda)\n",
    "clfs['Xdawn + MDM'] = make_pipeline(XdawnCovariances(n_components,\n",
    "                            estimator='oas'), MDM())\n",
    "clfs['Xdawn + SVM'] = make_pipeline(XdawnCovariances(n_components, estimator = 'oas'), Vectorizer(), svc)\n",
    "\n",
    "print(clfs)\n",
    "# Cross validator\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=27)\n",
    "\n",
    "for clf in clfs:\n",
    "    # Do cross-validation\n",
    "    preds = np.empty(len(y))\n",
    "    for train, test in cv.split(X, y):  #Xdawn takes in epoch object\n",
    "        print(X.shape, y.shape)\n",
    "        clfs[clf].fit(X[train], y[train])\n",
    "        preds[test] = clfs[clf].predict(X[test])\n",
    "\n",
    "    # Classification report\n",
    "    target_names = ['Non-target', 'targets']\n",
    "    report = classification_report(y, preds, target_names=target_names)\n",
    "    print(clf)\n",
    "    print(report)\n",
    "    \n",
    "# measure auc\n",
    "auc = []\n",
    "methods = []\n",
    "for m in clfs:\n",
    "    res = cross_val_score(clfs[m], X, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "    auc.extend(res)\n",
    "    methods.extend([m]*len(res))\n",
    "    \n",
    "results = pd.DataFrame(data=auc, columns=['AUC'])\n",
    "results['Method'] = methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "853f9f4d-d804-4150-88f6-2b6fd0e9d785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape:  (7164, 32, 410)\n",
      "y.shape:  (7164,)\n",
      "y.shape (7164,)\n",
      "---SVM---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Non-target       0.83      1.00      0.91      5970\n",
      "     targets       0.75      0.00      0.01      1194\n",
      "\n",
      "    accuracy                           0.83      7164\n",
      "   macro avg       0.79      0.50      0.46      7164\n",
      "weighted avg       0.82      0.83      0.76      7164\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from mne.preprocessing import Xdawn\n",
    "from pyriemann.estimation import XdawnCovariances\n",
    "from sklearn.metrics import classification_report\n",
    "from mne.decoding import Vectorizer\n",
    "from sklearn.model_selection import cross_val_score, StratifiedShuffleSplit\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "print(\"X.shape: \", X.shape)\n",
    "print(\"y.shape: \", y.shape)\n",
    "\n",
    "svc = SVC(kernel = 'rbf')\n",
    "n_components = 3\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=27)\n",
    "model = make_pipeline(XdawnCovariances(n_components, estimator='oas'), Vectorizer(), svc)\n",
    "\n",
    "preds = np.empty(len(y))\n",
    "for train, test in cv.split(X, y):  #Xdawn takes in epoch object\n",
    "    model.fit(X[train], y[train])\n",
    "    preds[test] = model.predict(X[test])\n",
    "    # print(\"preds.shape\", preds.shape)\n",
    "    \n",
    "# Classification report\n",
    "target_names = ['Non-target', 'targets']\n",
    "print(\"y.shape\", y.shape)\n",
    "print(\"---SVM---\")\n",
    "report = classification_report(y, preds, target_names=target_names)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6c561fa-32e1-4637-9d43-6c9cbed6a40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape:  (7164, 32, 410)\n",
      "y.shape:  (7164,)\n",
      "y.shape (7164,)\n",
      "---Regularized LDA---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Non-target       0.88      0.96      0.92      5970\n",
      "     targets       0.64      0.31      0.42      1194\n",
      "\n",
      "    accuracy                           0.86      7164\n",
      "   macro avg       0.76      0.64      0.67      7164\n",
      "weighted avg       0.84      0.86      0.83      7164\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from mne.preprocessing import Xdawn\n",
    "from pyriemann.estimation import XdawnCovariances\n",
    "from sklearn.metrics import classification_report\n",
    "from mne.decoding import Vectorizer\n",
    "from sklearn.model_selection import cross_val_score, StratifiedShuffleSplit\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "lda = LDA(shrinkage='auto', solver='eigen') #Regularized LDA\n",
    "\n",
    "print(\"X.shape: \", X.shape)\n",
    "print(\"y.shape: \", y.shape)\n",
    "\n",
    "n_components = 3\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=27)\n",
    "model = make_pipeline(XdawnCovariances(n_components, estimator='oas'), Vectorizer(), lda)\n",
    "\n",
    "preds = np.empty(len(y))\n",
    "for train, test in cv.split(X, y):  #Xdawn takes in epoch object\n",
    "    model.fit(X[train], y[train])\n",
    "    preds[test] = model.predict(X[test])\n",
    "    # print(\"preds.shape\", preds.shape)\n",
    "    \n",
    "# Classification report\n",
    "target_names = ['Non-target', 'targets']\n",
    "print(\"y.shape\", y.shape)\n",
    "print(\"---Regularized LDA---\")\n",
    "report = classification_report(y, preds, target_names=target_names)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02118e35-a5a9-4d6d-ac0b-3b2831909611",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
